# Sp√©cification de Fonctionnalit√© : Nouvelle Fonctionnalit√© TrendTrack

**Branche de Fonctionnalit√©** : `001-name-trendtrack-scraper`  
**Cr√©√©** : 2025-09-16  
**Statut** : Brouillon  
**Entr√©e** : Description utilisateur : "Ajouter une nouvelle fonctionnalit√© au scraper TrendTrack existant : au lieu d'aller chercher des shops sur trendtrack.io de mani√®re globale, permettre la recherche de shops sp√©cifiques pour r√©cup√©rer leurs informations. Cette fonctionnalit√© doit utiliser l'authentification API au lieu de l'authentification DOM, et int√©grer Playwright headless avec configuration stealth et syst√®me de pauses al√©atoires pour l'anti-d√©tection."

## Flux d'Ex√©cution (principal)
```
1. Analyser la description utilisateur depuis l'Entr√©e
   ‚Üí Si vide : ERREUR "Aucune description de fonctionnalit√© fournie"
2. Extraire les concepts cl√©s de la description
   ‚Üí Identifier : acteurs, actions, donn√©es, contraintes
3. Pour chaque aspect peu clair :
   ‚Üí Marquer avec [BESOIN DE CLARIFICATION : question sp√©cifique]
4. Remplir la section Sc√©narios Utilisateur & Tests
   ‚Üí Si aucun flux utilisateur clair : ERREUR "Impossible de d√©terminer les sc√©narios utilisateur"
5. G√©n√©rer les Exigences Fonctionnelles
   ‚Üí Chaque exigence doit √™tre testable
   ‚Üí Marquer les exigences ambigu√´s
6. Identifier les Entit√©s Cl√©s (si donn√©es impliqu√©es)
7. Ex√©cuter la Liste de V√©rification
   ‚Üí Si des [BESOIN DE CLARIFICATION] : AVERTISSEMENT "La spec a des incertitudes"
   ‚Üí Si d√©tails d'impl√©mentation trouv√©s : ERREUR "Supprimer les d√©tails techniques"
8. Retourner : SUCC√àS (spec pr√™te pour la planification)
```

---

## ‚ö° Guide Rapide
- ‚úÖ Se concentrer sur CE DONT les utilisateurs ont besoin et POURQUOI
- ‚ùå √âviter COMMENT impl√©menter (pas de stack technique, APIs, structure de code)
- üë• √âcrit pour les parties prenantes m√©tier, pas les d√©veloppeurs

### Exigences de Section
- **Sections obligatoires** : Doivent √™tre compl√©t√©es pour chaque fonctionnalit√©
- **Sections optionnelles** : Inclure seulement quand pertinent pour la fonctionnalit√©
- Quand une section ne s'applique pas, la supprimer enti√®rement (ne pas laisser comme "N/A")

### Pour la G√©n√©ration IA
Lors de la cr√©ation de cette spec √† partir d'une invite utilisateur :
1. **Marquer toutes les ambigu√Øt√©s** : Utiliser [BESOIN DE CLARIFICATION : question sp√©cifique] pour toute supposition n√©cessaire
2. **Ne pas deviner** : Si l'invite ne sp√©cifie pas quelque chose (ex: "syst√®me de connexion" sans m√©thode d'auth), le marquer
3. **Penser comme un testeur** : Toute exigence vague devrait √©chouer √† l'√©l√©ment "testable et non ambigu" de la liste de v√©rification
4. **Zones commun√©ment sous-sp√©cifi√©es** :
   - Types d'utilisateurs et permissions
   - Politiques de r√©tention/suppression de donn√©es
   - Objectifs de performance et √©chelle
   - Comportements de gestion d'erreurs
   - Exigences d'int√©gration
   - Besoins de s√©curit√©/conformit√©

---

## Sc√©narios Utilisateur & Tests *(obligatoire)*

### Histoire Utilisateur Principale
En tant qu'analyste m√©tier, je veux pouvoir rechercher des shops sp√©cifiques sur TrendTrack au lieu de faire une recherche globale, afin de pouvoir cibler pr√©cis√©ment les domaines qui m'int√©ressent et r√©cup√©rer leurs informations de mani√®re plus efficace et discr√®te.

### Sc√©narios d'Acceptation
1. **√âtant donn√©** un domaine sp√©cifique √† rechercher, **Quand** j'initie la recherche sur TrendTrack, **Alors** le syst√®me devrait s'authentifier via API et rechercher ce domaine sp√©cifique
2. **√âtant donn√©** une recherche de domaine sp√©cifique, **Quand** le syst√®me trouve des r√©sultats, **Alors** il devrait extraire les donn√©es de la premi√®re ligne correspondante du tableau
3. **√âtant donn√©** des donn√©es extraites d'un domaine sp√©cifique, **Quand** le syst√®me a r√©cup√©r√© les informations, **Alors** il devrait les stocker dans la base de donn√©es avec un statut vide
4. **√âtant donn√©** une recherche de domaine qui n'existe pas, **Quand** le syst√®me ne trouve aucun r√©sultat, **Alors** il devrait g√©rer gracieusement cette situation sans erreur
5. **√âtant donn√©** un syst√®me de pauses al√©atoires, **Quand** le syst√®me effectue des requ√™tes, **Alors** il devrait appliquer des d√©lais al√©atoires pour √©viter la d√©tection

### Cas Limites
- Que se passe-t-il quand l'authentification API TrendTrack √©choue ?
- Comment le syst√®me g√®re-t-il les domaines qui n'existent pas sur TrendTrack ?
- Que se passe-t-il quand la recherche ne retourne aucun r√©sultat ?
- Comment le syst√®me g√®re-t-il les limitations de d√©bit de TrendTrack ?
- Que se passe-t-il quand le syst√®me de pauses al√©atoires est d√©tect√© ?

## Exigences *(obligatoire)*

### Exigences Fonctionnelles

#### Architecture du Syst√®me Existant
- **EF-001** : Le syst√®me TrendTrack DOIT r√©cup√©rer des shops depuis trendtrack.io et les ins√©rer en base avec un statut vide
- **EF-002** : Le syst√®me SEM DOIT prendre les shops avec statuts vide ou partial depuis la base et les enrichir avec des m√©triques MyToolsPlan
- **EF-003** : Les deux syst√®mes DOIVENT partager la m√™me base de donn√©es h√©berg√©e dans trendtrack-scraper-final
- **EF-004** : L'API DOIT √™tre h√©berg√©e dans sem-scraper-final pour interagir avec la base de donn√©es partag√©e
- **EF-005** : Le syst√®me TrendTrack existant DOIT utiliser l'authentification DOM pour acc√©der √† trendtrack.io
- **EF-006** : Le syst√®me SEM existant DOIT utiliser l'authentification MyToolsPlan pour enrichir les m√©triques

#### Nouvelles Fonctionnalit√©s TrendTrack (√Ä D√©velopper)
- **NF-002** : Le syst√®me TrendTrack DOIT impl√©menter une authentification bas√©e sur API au lieu de l'authentification DOM existante
- **NF-003** : Le syst√®me TrendTrack DOIT utiliser Playwright headless avec configuration stealth pour √©viter la d√©tection
- **NF-004** : Le syst√®me TrendTrack DOIT impl√©menter un syst√®me de pauses al√©atoires avec des d√©lais configurables pour l'anti-d√©tection
- **NF-005** : Le syst√®me TrendTrack DOIT maintenir une architecture de fichiers claire s√©parant le scraping traditionnel du scraping par domaine sp√©cifique
- **NF-006** : Le syst√®me TrendTrack DOIT r√©utiliser les s√©lecteurs HTML existants pour les r√©sultats de recherche par domaine sp√©cifique
- **NF-007** : Le syst√®me TrendTrack DOIT stocker les r√©sultats de recherche par domaine sp√©cifique dans la m√™me base de donn√©es que le scraping traditionnel
- **NF-008** : Le syst√®me TrendTrack DOIT traiter un domaine √† la fois pour les recherches par domaine sp√©cifique
- **NF-009** : Le syst√®me TrendTrack DOIT extraire les donn√©es de la premi√®re ligne correspondante dans le tableau de r√©sultats de recherche

### Entit√©s Cl√©s *(inclure si la fonctionnalit√© implique des donn√©es)*
- **Shop TrendTrack** : Repr√©sente un shop r√©cup√©r√© depuis TrendTrack, contient l'URL, le nom, et le statut de traitement (vide initialement)
- **Recherche par Domaine** : Repr√©sente une recherche sp√©cifique d'un domaine sur TrendTrack au lieu d'une recherche globale
- **Base de Donn√©es Partag√©e** : Base SQLite h√©berg√©e dans trendtrack-scraper-final, partag√©e entre les syst√®mes TrendTrack et SEM
- **Authentification API** : Syst√®me d'authentification bas√© sur API pour TrendTrack, rempla√ßant l'authentification DOM existante

---

## Liste de V√©rification de R√©vision & Acceptation
*PORTE : V√©rifications automatis√©es ex√©cut√©es pendant main()*

### Qualit√© du Contenu
- [x] Aucun d√©tail d'impl√©mentation (langages, frameworks, APIs)
- [x] Concentr√© sur la valeur utilisateur et les besoins m√©tier
- [x] √âcrit pour les parties prenantes non-techniques
- [x] Toutes les sections obligatoires compl√©t√©es

### Compl√©tude des Exigences
- [x] Aucun marqueur [BESOIN DE CLARIFICATION] ne reste
- [x] Les exigences sont testables et non ambigu√´s
- [x] Les crit√®res de succ√®s sont mesurables
- [x] La port√©e est clairement d√©limit√©e
- [x] Les d√©pendances et suppositions identifi√©es

---

## Statut d'Ex√©cution
*Mis √† jour par main() pendant le traitement*

- [x] Description utilisateur analys√©e
- [x] Concepts cl√©s extraits
- [x] Ambigu√Øt√©s marqu√©es
- [x] Sc√©narios utilisateur d√©finis
- [x] Exigences g√©n√©r√©es
- [x] Entit√©s identifi√©es
- [x] Liste de v√©rification de r√©vision pass√©e
- [x] Analyse des structures de bases de donn√©es compl√©t√©e
- [x] Analyse des champs aliment√©s vs non aliment√©s termin√©e
- [x] T√¢ches de migration ajout√©es (T046-T050)

---

## Rapports d'Analyse Technique

### üìä **Analyses R√©alis√©es**
- **[Comparaison des Structures de Bases de Donn√©es](../../docs/analysis/database_structure_comparison.md)**: Analyse comparative entre les structures production et test
- **[Analyse des Champs Aliment√©s vs Non Aliment√©s](../../docs/analysis/field_analysis_report.md)**: Identification des gaps entre structure finale et code actuel

### üéØ **D√©couvertes Cl√©s**
- **7 types de donn√©es incorrects** identifi√©s n√©cessitant une migration
- **11 champs manquants** dans la structure finale non aliment√©s par le code actuel
- **Structure test sup√©rieure** avec types optimis√©s et nouvelles fonctionnalit√©s

### üìã **T√¢ches de Migration Ajout√©es**
- **T046**: Migration des types de donn√©es (P0)
- **T047**: Ajout des champs manquants (P1)  
- **T048**: Mise √† jour du code de scraping (P1)
- **T049**: Script de migration complet (P0)
- **T050**: Validation post-migration (P1)

---

**Feature Branch**: `001-name-trendtrack-scraper`  
**Created**: 2025-09-16  
**Status**: Draft  
**Input**: User description: "Syst√®me de scraping automatis√© pour r√©cup√©rer les m√©triques de performance des sites web via MyToolsPlan. Le syst√®me utilise une approche hybride combinant APIs et DOM scraping pour une r√©cup√©ration maximale des donn√©es. Fonctionnalit√©s principales: authentification unifi√©e, r√©cup√©ration de m√©triques (traffic organique, payant, bounce rate, dur√©e de visite, conversion rate), syst√®me de workers parall√®les, validation adaptative des donn√©es, gestion des statuts (completed/partial/failed/na), monitoring et d√©bogage int√©gr√©s."

## Execution Flow (main)
```
1. Parse user description from Input
   ‚Üí If empty: ERROR "No feature description provided"
2. Extract key concepts from description
   ‚Üí Identify: actors, actions, data, constraints
3. For each unclear aspect:
   ‚Üí Mark with [NEEDS CLARIFICATION: specific question]
4. Fill User Scenarios & Testing section
   ‚Üí If no clear user flow: ERROR "Cannot determine user scenarios"
5. Generate Functional Requirements
   ‚Üí Each requirement must be testable
   ‚Üí Mark ambiguous requirements
6. Identify Key Entities (if data involved)
7. Run Review Checklist
   ‚Üí If any [NEEDS CLARIFICATION]: WARN "Spec has uncertainties"
   ‚Üí If implementation details found: ERROR "Remove tech details"
8. Return: SUCCESS (spec ready for planning)
```

---

## ‚ö° Quick Guidelines
- ‚úÖ Focus on WHAT users need and WHY
- ‚ùå Avoid HOW to implement (no tech stack, APIs, code structure)
- üë• Written for business stakeholders, not developers

### Section Requirements
- **Mandatory sections**: Must be completed for every feature
- **Optional sections**: Include only when relevant to the feature
- When a section doesn't apply, remove it entirely (don't leave as "N/A")

### For AI Generation
When creating this spec from a user prompt:
1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] for any assumption you'd need to make
2. **Don't guess**: If the prompt doesn't specify something (e.g., "login system" without auth method), mark it
3. **Think like a tester**: Every vague requirement should fail the "testable and unambiguous" checklist item
4. **Common underspecified areas**:
   - User types and permissions
   - Data retention/deletion policies  
   - Performance targets and scale
   - Error handling behaviors
   - Integration requirements
   - Security/compliance needs

---

## User Scenarios & Testing *(mandatory)*

### Primary User Story
As a business analyst, I want to automatically collect website performance metrics from MyToolsPlan via the Scraper SEM Parall√®le so that I can analyze competitor performance and market trends without manual data collection.

### Acceptance Scenarios
1. **Given** a list of target websites, **When** I initiate the scraping process, **Then** the system should automatically authenticate and collect all available metrics for each website
2. **Given** websites with varying data availability, **When** the system encounters missing metrics, **Then** it should mark the website status as "partial" and continue processing other websites
3. **Given** a website with complete data, **When** all metrics are successfully collected, **Then** the system should mark the website status as "completed"
4. **Given** a website with very low traffic, **When** the system determines traffic is below threshold, **Then** it should mark the website status as "na" (not applicable)
5. **Given** a failed scraping attempt, **When** the system encounters an error, **Then** it should mark the website status as "failed" and log the error details

### Edge Cases
- What happens when authentication fails during the scraping process?
- How does the system handle websites that are temporarily unavailable?
- What occurs when a website has no available metrics data?
- How does the system manage rate limiting or API quotas?
- What happens when the system encounters websites with unusual data formats?

## Requirements *(mandatory)*

### Functional Requirements
- **FR-001**: System MUST automatically authenticate with data sources using provided credentials
- **FR-002**: System MUST collect organic search traffic metrics for each target website
- **FR-003**: System MUST collect paid search traffic metrics for each target website
- **FR-004**: System MUST collect bounce rate metrics for each target website
- **FR-005**: System MUST collect average visit duration metrics for each target website
- **FR-006**: System MUST collect conversion rate metrics for each target website
- **FR-007**: System MUST collect branded traffic metrics for each target website
- **FR-008**: System MUST calculate percentage of branded traffic automatically
- **FR-009**: System MUST process multiple websites simultaneously using parallel workers
- **FR-010**: System MUST validate collected metrics and determine website status (completed/partial/failed/na)
- **FR-011**: System MUST store all collected metrics in a persistent data store
- **FR-012**: System MUST provide real-time monitoring and logging of scraping progress
- **FR-013**: System MUST handle authentication failures gracefully and retry with appropriate delays
- **FR-014**: System MUST skip websites that have been recently processed to avoid unnecessary re-scraping
- **FR-015**: System MUST provide detailed error reporting for failed scraping attempts
- **FR-016**: System MUST support filtering websites by processing status for targeted re-processing
- **FR-017**: System MUST automatically retry failed scraping attempts up to 3 times with progressive delays
- **FR-018**: System MUST handle websites with organic traffic below 1000 as "na" status
- **FR-019**: System MUST provide data export capabilities for collected metrics
- **FR-020**: System MUST collect visits metrics (mapped from traffic via organic.OverviewTrend)
- **FR-021**: System MUST calculate percent_branded_traffic as decimal value (branded_traffic / visits)
- **FR-022**: System MUST use adaptive validation logic that counts all 8 metrics dynamically
- **FR-023**: System MUST avoid re-scraping websites with "completed" status unless older than 24 hours

### Key Entities *(include if feature involves data)*
- **Website**: Represents a target website for metric collection, contains URL, processing status, and metadata
- **Metrics**: Represents collected performance data including organic traffic, paid search traffic, visits, bounce rate, average visit duration, branded traffic, conversion rate, and percent branded traffic (8 total metrics)
- **Scraping Session**: Represents a processing run that includes multiple websites, workers, and overall status
- **Worker**: Represents a parallel processing unit that handles a subset of websites during a scraping session

---

## Review & Acceptance Checklist
*GATE: Automated checks run during main() execution*

### Content Quality
- [x] No implementation details (languages, frameworks, APIs)
- [x] Focused on user value and business needs
- [x] Written for non-technical stakeholders
- [x] All mandatory sections completed

### Requirement Completeness
- [x] No [NEEDS CLARIFICATION] markers remain
- [x] Requirements are testable and unambiguous  
- [x] Success criteria are measurable
- [x] Scope is clearly bounded
- [x] Dependencies and assumptions identified

---

## Execution Status
*Updated by main() during processing*

- [x] User description parsed
- [x] Key concepts extracted
- [x] Ambiguities marked
- [x] User scenarios defined
- [x] Requirements generated
- [x] Entities identified
- [x] Review checklist passed

---
