#!/usr/bin/env python3
"""
Scraper traditionnel pour les mÃ©triques Visits et Purchase Conversion
InspirÃ© du code SemrushLegoScraper fourni par l'utilisateur
"""

import asyncio
from playwright.async_api import async_playwright
import re
import json
import time
import logging
from typing import Dict, Optional
from datetime import datetime, timezone

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TraditionalVisitsConversionScraper:
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.page = None
        self.browser = None
        self.playwright = None
        
    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            ]
        )
        self.page = await self.browser.new_page()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
    
    async def login_semrush(self, email: str, password: str):
        """Se connecter Ã  Semrush"""
        logger.info("ğŸ”‘ Connexion Ã  Semrush...")
        
        try:
            await self.page.goto("https://sam.mytoolsplan.xyz/login/")
            
            # Remplir le formulaire de login
            await self.page.fill('input[name="email"]', email)
            await self.page.fill('input[name="password"]', password)
            
            # Cliquer sur le bouton de connexion
            await self.page.click('button[type="submit"]')
            
            # Attendre la redirection
            await self.page.wait_for_url("**/dashboard**", timeout=30000)
            logger.info("âœ… ConnectÃ© avec succÃ¨s!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur de connexion: {e}")
            return False
        
    async def scrape_visits_conversion_metrics(self, domain: str) -> Dict:
        """Scraper les mÃ©triques Visits et Purchase Conversion pour un domaine"""
        logger.info(f"ğŸ¯ Scraping des mÃ©triques Visits/Conversion pour {domain}...")
        
        try:
            # Aller sur la page Traffic Analytics
            url = f"https://sam.mytoolsplan.xyz/analytics/traffic/overview/?q={domain}"
            await self.page.goto(url, wait_until="networkidle")
            
            # Attendre le chargement des donnÃ©es
            logger.info("â³ Attente du chargement des donnÃ©es...")
            await asyncio.sleep(5)
            
            # Attendre que le tableau soit visible
            try:
                await self.page.wait_for_selector('[role="grid"], table, [data-testid*="table"]', timeout=20000)
            except:
                logger.warning("âš ï¸ Tableau non trouvÃ©, tentative avec sÃ©lecteurs alternatifs...")
            
            # ExÃ©cuter le script JavaScript pour extraire les donnÃ©es
            metrics_data = await self.page.evaluate(f"""
                () => {{
                    const result = {{
                        domain: '{domain}',
                        visits: null,
                        purchaseConversion: null,
                        allData: [],
                        found: false,
                        timestamp: new Date().toISOString()
                    }};
                    
                    console.log('ğŸ” Recherche donnÃ©es pour {domain}...');
                    
                    // Fonction pour parser les valeurs de trafic
                    function parseTrafficValue(text) {{
                        const cleanText = text.replace(/[â†‘â†“\\s]/g, '');
                        const multipliers = {{ 'K': 1000, 'M': 1000000, 'B': 1000000000 }};
                        
                        const match = cleanText.match(/^(\\d+\\.?\\d*)([KMB]?)$/);
                        if (match) {{
                            const number = parseFloat(match[1]);
                            const multiplier = multipliers[match[2]] || 1;
                            return Math.round(number * multiplier);
                        }}
                        return 0;
                    }}
                    
                    // 1. Chercher dans toutes les lignes de tableau
                    const allRows = document.querySelectorAll('tr, [role="row"], .table-row');
                    
                    for (const row of allRows) {{
                        const rowText = row.textContent || '';
                        
                        if (rowText.toLowerCase().includes('{domain.lower()}')) {{
                            console.log('ğŸ¯ Ligne {domain} trouvÃ©e!');
                            result.found = true;
                            result.domain = '{domain}';
                            
                            // Extraire toutes les cellules
                            const cells = row.querySelectorAll('td, [role="gridcell"], [role="cell"], .cell');
                            const cellTexts = Array.from(cells).map(cell => cell.textContent.trim());
                            
                            result.allData = cellTexts;
                            console.log('ğŸ“Š Cellules trouvÃ©es:', cellTexts);
                            
                            // Parser chaque cellule
                            cellTexts.forEach((cellText, index) => {{
                                // Visits (grands nombres avec M/B)
                                if (cellText.match(/^\\d+\\.?\\d*[MB]/)) {{
                                    const number = parseTrafficValue(cellText);
                                    if (number > 10000000 && !result.visits) {{ // > 10M
                                        result.visits = number;
                                    }}
                                }}
                                
                                // Pourcentages de conversion (petits %)
                                if (cellText.match(/^\\d+\\.\\d+%/) && cellText.includes('.')) {{
                                    const rate = parseFloat(cellText.replace('%', '').replace(/[â†‘â†“]/, ''));
                                    if (rate < 10 && !result.purchaseConversion) {{
                                        result.purchaseConversion = rate;
                                    }}
                                }}
                            }});
                            
                            break;
                        }}
                    }}
                    
                    // 2. Si pas trouvÃ©, chercher dans les mÃ©triques gÃ©nÃ©rales
                    if (!result.found) {{
                        const summaryCards = document.querySelectorAll('[data-testid*="metric"], [data-testid*="summary"], .metric-card');
                        
                        summaryCards.forEach(card => {{
                            const text = card.textContent;
                            if (text.toLowerCase().includes('{domain.lower()}')) {{
                                result.found = true;
                                result.allData.push(text);
                            }}
                        }});
                    }}
                    
                    return result;
                }}
            """)
            
            return metrics_data
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors du scraping de {domain}: {e}")
            return {
                'domain': domain,
                'visits': None,
                'purchaseConversion': None,
                'allData': [],
                'found': False,
                'error': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
    
    def parse_traffic_value(self, text: str) -> int:
        """Parse les valeurs de trafic (45.6M -> 45600000)"""
        if not text:
            return 0
            
        clean_text = re.sub(r'[â†‘â†“\s]', '', text)
        multipliers = {'K': 1000, 'M': 1000000, 'B': 1000000000}
        
        match = re.match(r'^(\d+\.?\d*)([KMB]?)$', clean_text)
        if match:
            number = float(match.group(1))
            multiplier = multipliers.get(match.group(2), 1)
            return int(number * multiplier)
        return 0

    async def scrape_multiple_domains(self, domains: list) -> Dict:
        """Scraper les mÃ©triques pour plusieurs domaines"""
        results = {}
        
        for domain in domains:
            logger.info(f"ğŸ”„ Traitement de {domain}...")
            metrics = await self.scrape_visits_conversion_metrics(domain)
            results[domain] = metrics
            
            # Pause entre les requÃªtes pour Ã©viter la dÃ©tection
            await asyncio.sleep(2)
        
        return results

    async def take_screenshot(self, filename: str = "traffic_analytics.png"):
        """Prendre une capture d'Ã©cran"""
        try:
            await self.page.screenshot(path=filename, full_page=True)
            logger.info(f"ğŸ“¸ Capture d'Ã©cran sauvÃ©e: {filename}")
        except Exception as e:
            logger.error(f"âŒ Erreur capture d'Ã©cran: {e}")

# ğŸ¯ FONCTION PRINCIPALE DE TEST
async def test_scraper():
    """Test du scraper avec quelques domaines"""
    
    # Domaines de test
    test_domains = [
        "spanx.com",
        "cakesbody.com", 
        "lego.com",
        "nike.com"
    ]
    
    async with TraditionalVisitsConversionScraper(headless=True) as scraper:
        # Optionnel: Se connecter (dÃ©commentez et ajoutez vos credentials)
        # await scraper.login_semrush("your_email@example.com", "your_password")
        
        logger.info("ğŸš€ DÃ©but du test du scraper traditionnel...")
        
        # Scraper les donnÃ©es pour tous les domaines
        results = await scraper.scrape_multiple_domains(test_domains)
        
        # Afficher les rÃ©sultats
        logger.info("\nğŸ‰ === RÃ‰SULTATS DU SCRAPING ===")
        
        for domain, data in results.items():
            logger.info(f"\nğŸŒ Domaine: {domain}")
            logger.info(f"ğŸ“Š Visits: {data['visits']:,}" if data['visits'] else "ğŸ“Š Visits: N/A")
            logger.info(f"ğŸ’° Purchase Conversion: {data['purchaseConversion']}%" if data['purchaseConversion'] else "ğŸ’° Purchase Conversion: N/A")
            logger.info(f"âœ… TrouvÃ©: {'Oui' if data['found'] else 'Non'}")
            
            if data.get('error'):
                logger.error(f"âŒ Erreur: {data['error']}")
        
        # Capture d'Ã©cran
        await scraper.take_screenshot("traffic_analytics_test.png")
        
        # Sauvegarder en JSON
        with open('visits_conversion_metrics.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        logger.info("ğŸ’¾ DonnÃ©es sauvÃ©es dans visits_conversion_metrics.json")
        
        return results

if __name__ == "__main__":
    asyncio.run(test_scraper())
