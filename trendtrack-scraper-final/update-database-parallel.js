/**
 * Script de mise √† jour PARALL√àLE de la base de donn√©es
 * Architecture en 2 phases :
 * 1. Extraction de toutes les donn√©es du tableau (sans navigation)
 * 2. Extraction parall√®le des d√©tails avec mise √† jour incr√©mentale
 */

import { WebScraper } from './src/scraper.js';
import { TrendTrackExtractor } from './src/extractors/trendtrack-extractor.js';
import { DatabaseManager } from './src/database/database-manager.js';
import { ShopRepository } from './src/database/shop-repository.js';
import fs from 'fs';
import path from 'path';

const LOG_PROGRESS_FILE = 'logs/update-progress-parallel.log';

function logProgress(msg) {
  const line = `[${new Date().toISOString()}] ${msg}\n`;
  fs.appendFileSync(LOG_PROGRESS_FILE, line);
  console.log(msg);
}

// Nettoie le fichier de log au d√©but
fs.writeFileSync(LOG_PROGRESS_FILE, '');

/**
 * PHASE 1: Extraction de toutes les donn√©es du tableau
 * Sans navigation vers les pages de d√©tail
 */
async function extractTableDataOnly(extractor, pages = 5) {
  logProgress('üìã PHASE 1: Extraction des donn√©es du tableau uniquement...');
  
  const allTableData = [];
  
  for (let page = 1; page <= pages; page++) {
    logProgress(`‚û°Ô∏è  Extraction page ${page}/${pages}...`);
    
    try {
      // Navigation vers la page
      const navSuccess = await extractor.navigateToTrendingShops(page);
      if (!navSuccess) {
        logProgress(`‚ùå Navigation √©chou√©e pour la page ${page}`);
        continue;
      }
      
      // Extraction des donn√©es du tableau uniquement (sans navigation vers d√©tails)
      const pageData = await extractor.extractAllShopsData(false); // false = pas de m√©triques avanc√©es
      logProgress(`‚úÖ Page ${page}: ${pageData.length} boutiques extraites du tableau`);
      
      allTableData.push(...pageData);
      
      // Pause entre les pages
      if (page < pages) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
      
    } catch (error) {
      logProgress(`‚ùå Erreur page ${page}: ${error.message}`);
      continue;
    }
  }
  
  logProgress(`‚úÖ PHASE 1 TERMIN√âE: ${allTableData.length} boutiques extraites du tableau`);
  return allTableData;
}

/**
 * PHASE 2: Sauvegarde imm√©diate en base avec IDs g√©n√©r√©s
 */
async function saveTableDataToDatabase(shopRepo, tableData) {
  logProgress('üíæ PHASE 2: Sauvegarde imm√©diate des donn√©es du tableau...');
  
  const savedShops = [];
  const batchSize = 20;
  
  for (let i = 0; i < tableData.length; i += batchSize) {
    const batch = tableData.slice(i, i + batchSize);
    
    const batchPromises = batch.map(async (shopData) => {
      try {
        // V√©rifier si le shop existe d√©j√†
        const existingShop = await shopRepo.getByUrl(shopData.shopUrl || shopData.shop_url);
        
        if (existingShop) {
          logProgress(`‚è≠Ô∏è Shop existant: ${shopData.shopName || shopData.shop_name} - Mise √† jour`);
          // Mettre √† jour les donn√©es du tableau
          await shopRepo.updateTableData(existingShop.id, shopData);
          return { ...existingShop, updated: true };
        } else {
          // Nouveau shop - insertion avec ID g√©n√©r√©
          const shopId = await shopRepo.insertTableData(shopData);
          if (shopId) {
            const newShop = await shopRepo.getById(shopId);
            logProgress(`üÜï Nouveau shop: ${shopData.shopName || shopData.shop_name} - ID: ${shopId}`);
            return { ...newShop, updated: false };
          }
        }
      } catch (error) {
        logProgress(`‚ùå Erreur sauvegarde: ${error.message}`);
        return null;
      }
    });
    
    const batchResults = await Promise.all(batchPromises);
    savedShops.push(...batchResults.filter(shop => shop !== null));
    
    logProgress(`üì¶ Lot ${Math.floor(i / batchSize) + 1}/${Math.ceil(tableData.length / batchSize)} sauvegard√©`);
  }
  
  logProgress(`‚úÖ PHASE 2 TERMIN√âE: ${savedShops.length} boutiques sauvegard√©es en base`);
  return savedShops;
}

/**
 * PHASE 3: Extraction parall√®le des d√©tails avec liaison par URL
 */
async function extractDetailsInParallel(extractor, savedShops, maxConcurrency = 5) {
  logProgress('üîç PHASE 3: Extraction parall√®le des d√©tails...');
  
  const results = {
    success: 0,
    errors: 0,
    skipped: 0
  };
  
  // Traitement par lots pour √©viter la surcharge
  for (let i = 0; i < savedShops.length; i += maxConcurrency) {
    const batch = savedShops.slice(i, i + maxConcurrency);
    
    const batchPromises = batch.map(async (shop) => {
      try {
        logProgress(`üîç Extraction d√©tails: ${shop.shop_name} (ID: ${shop.id})`);
        
        // Navigation vers la page de d√©tail
        const detailSuccess = await extractor.navigateToShopDetail(shop.shop_url);
        if (!detailSuccess) {
          logProgress(`‚ö†Ô∏è Navigation d√©tail √©chou√©e: ${shop.shop_name}`);
          return { success: false, error: 'Navigation √©chou√©e' };
        }
        
        // Extraction des d√©tails
        const detailData = await extractor.extractShopDetails();
        
        // Retour √† la page liste (sans perdre la session)
        await extractor.returnToListPage();
        
        return {
          success: true,
          shopId: shop.id,
          shopUrl: shop.shop_url,
          detailData
        };
        
      } catch (error) {
        logProgress(`‚ùå Erreur d√©tails ${shop.shop_name}: ${error.message}`);
        return { success: false, error: error.message };
      }
    });
    
    const batchResults = await Promise.all(batchPromises);
    
    // Traitement des r√©sultats du lot
    for (const result of batchResults) {
      if (result.success) {
        results.success++;
        logProgress(`‚úÖ D√©tails extraits: ${result.shopUrl}`);
      } else {
        results.errors++;
        logProgress(`‚ùå Erreur d√©tails: ${result.error}`);
      }
    }
    
    logProgress(`üì¶ Lot d√©tails ${Math.floor(i / maxConcurrency) + 1}/${Math.ceil(savedShops.length / maxConcurrency)} trait√©`);
    
    // Pause entre les lots
    if (i + maxConcurrency < savedShops.length) {
      await new Promise(resolve => setTimeout(resolve, 2000));
    }
  }
  
  logProgress(`‚úÖ PHASE 3 TERMIN√âE: ${results.success} succ√®s, ${results.errors} erreurs`);
  return results;
}

/**
 * PHASE 4: Mise √† jour incr√©mentale des m√©triques
 */
async function updateMetricsIncremental(shopRepo, detailResults) {
  logProgress('üìä PHASE 4: Mise √† jour incr√©mentale des m√©triques...');
  
  const updatePromises = detailResults.map(async (result) => {
    if (result.success && result.detailData) {
      try {
        await shopRepo.updateDetailMetrics(result.shopId, result.detailData);
        logProgress(`üìä M√©triques mises √† jour: ${result.shopUrl}`);
        return { success: true, shopId: result.shopId };
      } catch (error) {
        logProgress(`‚ùå Erreur mise √† jour m√©triques: ${error.message}`);
        return { success: false, error: error.message };
      }
    }
    return { success: false, error: 'Pas de donn√©es de d√©tail' };
  });
  
  const updateResults = await Promise.all(updatePromises);
  const successCount = updateResults.filter(r => r.success).length;
  
  logProgress(`‚úÖ PHASE 4 TERMIN√âE: ${successCount} m√©triques mises √† jour`);
  return updateResults;
}

/**
 * Fonction principale avec architecture parall√®le
 */
async function updateDatabaseParallel() {
  logProgress('üöÄ D√âMARRAGE - Architecture parall√®le TrendTrack');
  
  let scraper = null;
  let extractor = null;
  let dbManager = null;
  let shopRepo = null;
  
  try {
    // Initialiser le scraper
    logProgress('üöÄ Initialisation du scraper...');
    scraper = new WebScraper();
    await scraper.init();
    extractor = new TrendTrackExtractor(scraper.page, scraper.errorHandler);
    
    // Initialiser la base de donn√©es
    logProgress('üóÑÔ∏è Initialisation de la base de donn√©es...');
    dbManager = new DatabaseManager();
    await dbManager.init();
    shopRepo = new ShopRepository(dbManager);
    
    // Connexion √† TrendTrack
    logProgress('üîë Connexion √† TrendTrack...');
    const loginSuccess = await extractor.login('seif.alyakoob@gmail.com', 'Toulouse31!');
    
    if (!loginSuccess) {
      logProgress('‚ùå √âchec de la connexion');
      return;
    }
    
    // PHASE 1: Extraction des donn√©es du tableau
    const tableData = await extractTableDataOnly(extractor, 5);
    
    if (!tableData || tableData.length === 0) {
      logProgress('‚ùå Aucune donn√©e du tableau extraite');
      return;
    }
    
    // Export debug des donn√©es du tableau
    fs.writeFileSync('export-table-data.json', JSON.stringify(tableData, null, 2));
    
    // PHASE 2: Sauvegarde imm√©diate en base
    const savedShops = await saveTableDataToDatabase(shopRepo, tableData);
    
    if (!savedShops || savedShops.length === 0) {
      logProgress('‚ùå Aucune boutique sauvegard√©e');
      return;
    }
    
    // PHASE 3: Extraction parall√®le des d√©tails
    const detailResults = await extractDetailsInParallel(extractor, savedShops, 3);
    
    // PHASE 4: Mise √† jour incr√©mentale des m√©triques
    const metricResults = await updateMetricsIncremental(shopRepo, detailResults);
    
    // Statistiques finales
    logProgress('\nüìä STATISTIQUES FINALES - ARCHITECTURE PARALL√àLE:');
    logProgress('==================================================');
    logProgress(`üìã Donn√©es tableau extraites: ${tableData.length}`);
    logProgress(`üíæ Boutiques sauvegard√©es: ${savedShops.length}`);
    logProgress(`üîç D√©tails extraits avec succ√®s: ${detailResults.success}`);
    logProgress(`‚ùå Erreurs extraction d√©tails: ${detailResults.errors}`);
    logProgress(`üìä M√©triques mises √† jour: ${metricResults.filter(r => r.success).length}`);
    logProgress('‚úÖ Architecture parall√®le termin√©e avec succ√®s !');
    
  } catch (error) {
    logProgress(`‚ùå Erreur fatale: ${error.message}`);
    console.error('‚ùå Erreur d√©taill√©e:', error);
  } finally {
    // Fermer les connexions
    if (scraper) {
      try {
        await scraper.close();
        logProgress('üîö Fermeture du scraper...');
      } catch (error) {
        logProgress(`‚ö†Ô∏è  Erreur fermeture scraper: ${error.message}`);
      }
    }
    
    if (dbManager) {
      try {
        await dbManager.close();
        logProgress('üîí Connexion base de donn√©es ferm√©e');
      } catch (error) {
        logProgress(`‚ö†Ô∏è  Erreur fermeture base: ${error.message}`);
      }
    }
  }
}

// Ex√©cution du script
updateDatabaseParallel().catch(error => {
  console.error('‚ùå Erreur fatale:', error);
  process.exit(1);
});


