#!/usr/bin/env python3
import asyncio
from playwright.async_api import async_playwright
import os
import time

async def analyze_domain_overview():
    """Analyse complÃ¨te de la page Domain Overview pour identifier les sÃ©lecteurs"""
    
    print("ğŸ” ANALYSE PAGE DOMAIN OVERVIEW")
    print("=" * 50)
    
    async with async_playwright() as p:
        # Configuration Xvfb
        os.environ['DISPLAY'] = ':99'
        os.system('Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &')
        time.sleep(2)
        
        browser = await p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage']
        )
        
        page = await browser.new_page()
        
        try:
            # 1. LOGIN
            print("ğŸ” Ã‰tape 1: Connexion...")
            await page.goto('https://app.mytoolsplan.com/login', timeout=30000)
            await page.fill('input[name="amember_login"]', 'Semrush3my')
            await page.fill('input[name="amember_pass"]', 'afhznmd455!fhIhh7FHkd')
            await page.click('input[class="frm-submit"]')
            await page.wait_for_load_state('networkidle', timeout=30000)
            print("âœ… Login rÃ©ussi")
            
            # 2. NAVIGATION VERS DOMAIN OVERVIEW
            print("\nğŸŒ Ã‰tape 2: Navigation vers Domain Overview...")
            test_domain = "skims.com"
            await page.goto(f'https://app.mytoolsplan.com/domain-overview?domain={test_domain}', timeout=30000)
            print("âœ… Page Domain Overview chargÃ©e")
            
            # 3. ANALYSE COMPLÃˆTE DE LA PAGE
            print("\nğŸ“Š Ã‰tape 3: Analyse complÃ¨te de la page...")
            
            # RÃ©cupÃ©rer tout le HTML
            html_content = await page.content()
            
            # Analyser les Ã©lÃ©ments de texte
            print("\nğŸ” Ã‰LÃ‰MENTS DE TEXTE TROUVÃ‰S:")
            print("-" * 30)
            
            # Chercher des patterns de mÃ©triques
            text_elements = await page.query_selector_all('*')
            metric_keywords = [
                'traffic', 'bounce', 'duration', 'conversion', 'visit', 'branded', 'paid'
            ]
            
            found_metrics = []
            for element in text_elements[:100]:  # Limiter pour Ã©viter la surcharge
                try:
                    text = await element.text_content()
                    if text and len(text.strip()) > 0:
                        text_lower = text.lower()
                        for keyword in metric_keywords:
                            if keyword in text_lower:
                                found_metrics.append((text.strip()[:50], element.tag_name))
                                break
                except:
                    continue
            
            # Afficher les mÃ©triques trouvÃ©es
            for text, tag in found_metrics[:20]:
                print(f"   {tag}: '{text}'")
            
            # 4. ANALYSE DES STRUCTURES DE DONNÃ‰ES
            print("\nğŸ—ï¸ Ã‰TUDE DES STRUCTURES DE DONNÃ‰ES:")
            print("-" * 30)
            
            # Chercher des tableaux
            tables = await page.query_selector_all('table')
            print(f"ğŸ“‹ Nombre de tableaux trouvÃ©s: {len(tables)}")
            
            for i, table in enumerate(tables[:3]):
                try:
                    rows = await table.query_selector_all('tr')
                    print(f"   Tableau {i+1}: {len(rows)} lignes")
                    
                    # Analyser les en-tÃªtes
                    if rows:
                        headers = await rows[0].query_selector_all('th, td')
                        header_texts = []
                        for header in headers[:5]:
                            try:
                                text = await header.text_content()
                                header_texts.append(text.strip()[:20])
                            except:
                                continue
                        print(f"      En-tÃªtes: {header_texts}")
                except Exception as e:
                    print(f"      Erreur analyse tableau {i+1}: {e}")
            
            # 5. ANALYSE DES DIVS ET SECTIONS
            print("\nğŸ“¦ ANALYSE DES SECTIONS:")
            print("-" * 30)
            
            # Chercher des divs avec des classes spÃ©cifiques
            divs = await page.query_selector_all('div[class*="metric"], div[class*="data"], div[class*="stat"]')
            print(f"ğŸ“Š Divs avec classes mÃ©triques: {len(divs)}")
            
            for i, div in enumerate(divs[:5]):
                try:
                    class_attr = await div.get_attribute('class')
                    text = await div.text_content()
                    print(f"   Div {i+1} (class='{class_attr}'): '{text.strip()[:50]}'")
                except:
                    continue
            
            # 6. ANALYSE DES SPANS ET LABELS
            print("\nğŸ·ï¸ ANALYSE DES LABELS ET SPANS:")
            print("-" * 30)
            
            spans = await page.query_selector_all('span, label')
            metric_spans = []
            
            for span in spans[:50]:
                try:
                    text = await span.text_content()
                    if text and any(keyword in text.lower() for keyword in metric_keywords):
                        metric_spans.append(text.strip()[:40])
                except:
                    continue
            
            for span_text in metric_spans[:10]:
                print(f"   Span: '{span_text}'")
            
            # 7. SAUVEGARDE DU HTML POUR ANALYSE MANUELLE
            print("\nğŸ’¾ SAUVEGARDE DU HTML...")
            with open('/tmp/domain_overview_analysis.html', 'w', encoding='utf-8') as f:
                f.write(html_content)
            print("âœ… HTML sauvegardÃ© dans /tmp/domain_overview_analysis.html")
            
            # 8. RECHERCHE DE PATTERNS SPÃ‰CIFIQUES
            print("\nğŸ¯ RECHERCHE DE PATTERNS SPÃ‰CIFIQUES:")
            print("-" * 30)
            
            # Chercher des patterns comme "Organic Traffic: 2.5M"
            pattern_selectors = [
                'text=/.*[Tt]raffic.*:/',
                'text=/.*[Bb]ounce.*:/',
                'text=/.*[Dd]uration.*:/',
                'text=/.*[Cc]onversion.*:/',
                'text=/.*[Vv]isit.*:/'
            ]
            
            for pattern in pattern_selectors:
                try:
                    elements = await page.query_selector_all(pattern)
                    if elements:
                        print(f"   Pattern '{pattern}': {len(elements)} Ã©lÃ©ments trouvÃ©s")
                        for j, elem in enumerate(elements[:2]):
                            text = await elem.text_content()
                            print(f"      {j+1}: '{text.strip()[:50]}'")
                except Exception as e:
                    print(f"   Pattern '{pattern}': Erreur - {e}")
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©rale: {e}")
            print(f"   Type: {type(e).__name__}")
        
        finally:
            await browser.close()
            os.system('pkill Xvfb 2>/dev/null')
    
    print(f"\nğŸ¯ ANALYSE TERMINÃ‰E")
    print("=" * 50)
    print("ğŸ“ VÃ©rifiez le fichier HTML sauvegardÃ© pour une analyse manuelle")

if __name__ == "__main__":
    asyncio.run(analyze_domain_overview())
