#!/usr/bin/env python3
import os

def compare_scrapers():
    """Compare le scraper principal et le scraper intelligent"""
    
    print("ğŸ” COMPARAISON SCRAPER PRINCIPAL vs SCRAPER INTELLIGENT")
    print("=" * 60)
    
    # Chemins des fichiers
    main_scraper = "/home/ubuntu/sem-scraper-final/production_scraper.py"
    smart_scraper = "/home/ubuntu/trendtrack-scraper-final/scrape_smart_all.py"
    
    if not os.path.exists(main_scraper):
        print(f"âŒ Scraper principal non trouvÃ©: {main_scraper}")
        return
    
    if not os.path.exists(smart_scraper):
        print(f"âŒ Scraper intelligent non trouvÃ©: {smart_scraper}")
        return
    
    print("ğŸ“Š ANALYSE DES DIFFÃ‰RENCES...")
    print("-" * 40)
    
    # 1. COMPARAISON DES IMPORTS
    print("\n1ï¸âƒ£ IMPORTS:")
    print("-" * 20)
    
    with open(main_scraper, 'r') as f:
        main_content = f.read()
    
    with open(smart_scraper, 'r') as f:
        smart_content = f.read()
    
    # Imports du scraper principal
    main_imports = [line.strip() for line in main_content.split('\n') if line.strip().startswith('import') or line.strip().startswith('from')]
    print("ğŸ“¦ Scraper principal - Imports:")
    for imp in main_imports[:10]:
        print(f"   {imp}")
    
    # Imports du scraper intelligent
    smart_imports = [line.strip() for line in smart_content.split('\n') if line.strip().startswith('import') or line.strip().startswith('from')]
    print("\nğŸ“¦ Scraper intelligent - Imports:")
    for imp in smart_imports[:10]:
        print(f"   {imp}")
    
    # 2. COMPARAISON DES URLS
    print("\n2ï¸âƒ£ URLS ET DOMAINES:")
    print("-" * 20)
    
    # URLs dans le scraper principal
    main_urls = [line.strip() for line in main_content.split('\n') if 'mytoolsplan' in line and 'http' in line]
    print("ğŸŒ Scraper principal - URLs:")
    for url in main_urls[:5]:
        print(f"   {url}")
    
    # URLs dans le scraper intelligent
    smart_urls = [line.strip() for line in smart_content.split('\n') if 'mytoolsplan' in line and 'http' in line]
    print("\nğŸŒ Scraper intelligent - URLs:")
    for url in smart_urls[:5]:
        print(f"   {url}")
    
    # 3. COMPARAISON DES SÃ‰LECTEURS
    print("\n3ï¸âƒ£ SÃ‰LECTEURS:")
    print("-" * 20)
    
    # SÃ©lecteurs dans le scraper principal
    main_selectors = [line.strip() for line in main_content.split('\n') if 'wait_for_selector' in line or 'query_selector' in line or 'fill(' in line]
    print("ğŸ¯ Scraper principal - SÃ©lecteurs:")
    for sel in main_selectors[:8]:
        print(f"   {sel}")
    
    # SÃ©lecteurs dans le scraper intelligent
    smart_selectors = [line.strip() for line in smart_content.split('\n') if 'wait_for_selector' in line or 'query_selector' in line or 'fill(' in line]
    print("\nğŸ¯ Scraper intelligent - SÃ©lecteurs:")
    for sel in smart_selectors[:8]:
        print(f"   {sel}")
    
    # 4. COMPARAISON DES MÃ‰TRIQUES
    print("\n4ï¸âƒ£ MÃ‰TRIQUES ET LOGIQUE:")
    print("-" * 20)
    
    # MÃ©triques dans le scraper principal
    main_metrics = [line.strip() for line in main_content.split('\n') if 'organic_traffic' in line or 'bounce_rate' in line or 'paid_search_traffic' in line]
    print("ğŸ“Š Scraper principal - MÃ©triques:")
    for met in main_metrics[:5]:
        print(f"   {met}")
    
    # MÃ©triques dans le scraper intelligent
    smart_metrics = [line.strip() for line in smart_content.split('\n') if 'organic_traffic' in line or 'bounce_rate' in line or 'paid_search_traffic' in line]
    print("\nğŸ“Š Scraper intelligent - MÃ©triques:")
    for met in smart_metrics[:5]:
        print(f"   {met}")
    
    # 5. COMPARAISON DES FONCTIONS
    print("\n5ï¸âƒ£ FONCTIONS:")
    print("-" * 20)
    
    # Fonctions dans le scraper principal
    main_functions = [line.strip() for line in main_content.split('\n') if line.strip().startswith('def ')]
    print("ğŸ”§ Scraper principal - Fonctions:")
    for func in main_functions[:8]:
        print(f"   {func}")
    
    # Fonctions dans le scraper intelligent
    smart_functions = [line.strip() for line in smart_content.split('\n') if line.strip().startswith('def ')]
    print("\nğŸ”§ Scraper intelligent - Fonctions:")
    for func in smart_functions[:8]:
        print(f"   {func}")
    
    # 6. COMPARAISON DES CONFIGURATIONS
    print("\n6ï¸âƒ£ CONFIGURATIONS:")
    print("-" * 20)
    
    # Configurations dans le scraper principal
    main_config = [line.strip() for line in main_content.split('\n') if 'timeout' in line or 'headless' in line or 'args=' in line]
    print("âš™ï¸ Scraper principal - Configurations:")
    for config in main_config[:5]:
        print(f"   {config}")
    
    # Configurations dans le scraper intelligent
    smart_config = [line.strip() for line in smart_content.split('\n') if 'timeout' in line or 'headless' in line or 'args=' in line]
    print("\nâš™ï¸ Scraper intelligent - Configurations:")
    for config in smart_config[:5]:
        print(f"   {config}")
    
    print(f"\nğŸ¯ COMPARAISON TERMINÃ‰E")
    print("=" * 60)

if __name__ == "__main__":
    compare_scrapers()
