#!/usr/bin/env python3
"""
Script pour nettoyer les doublons dans la table analytics et corriger la structure
"""

import sqlite3
from datetime import datetime, timezone
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def fix_analytics_duplicates():
    """Nettoie les doublons et corrige la structure de la table analytics"""
    
    print("ğŸ”§ CORRECTION DES DOUBLONS DANS LA TABLE ANALYTICS")
    print("=" * 60)
    
    try:
        # Connexion Ã  la base
        conn = sqlite3.connect('/home/ubuntu/trendtrack-scraper-final/data/trendtrack.db')
        cursor = conn.cursor()
        
        print("\nğŸ“Š ANALYSE DE LA SITUATION ACTUELLE:")
        
        # Compter les entrÃ©es totales
        cursor.execute("SELECT COUNT(*) FROM analytics")
        total_entries = cursor.fetchone()[0]
        print(f"   Total des entrÃ©es: {total_entries}")
        
        # Compter les boutiques uniques
        cursor.execute("SELECT COUNT(DISTINCT shop_id) FROM analytics")
        unique_shops = cursor.fetchone()[0]
        print(f"   Boutiques uniques: {unique_shops}")
        
        # Compter les doublons
        cursor.execute("""
            SELECT COUNT(*) FROM (
                SELECT shop_id, COUNT(*) as count 
                FROM analytics 
                GROUP BY shop_id 
                HAVING COUNT(*) > 1
            )
        """)
        shops_with_duplicates = cursor.fetchone()[0]
        print(f"   Boutiques avec doublons: {shops_with_duplicates}")
        
        # Calculer l'espace perdu
        wasted_entries = total_entries - unique_shops
        print(f"   EntrÃ©es perdues (doublons): {wasted_entries}")
        
        print("\nğŸ§¹ PHASE 1: NETTOYAGE DES DOUBLONS")
        
        # Identifier les doublons pour chaque boutique
        cursor.execute("""
            SELECT shop_id, COUNT(*) as count 
            FROM analytics 
            GROUP BY shop_id 
            HAVING COUNT(*) > 1
            ORDER BY count DESC
        """)
        
        duplicates = cursor.fetchall()
        
        total_cleaned = 0
        
        for shop_id, count in duplicates:
            print(f"   Boutique {shop_id}: {count} entrÃ©es â†’ nettoyage...")
            
            # RÃ©cupÃ©rer toutes les entrÃ©es pour cette boutique
            cursor.execute("""
                SELECT id, updated_at, paid_search_traffic, organic_traffic, scraping_status
                FROM analytics 
                WHERE shop_id = ? 
                ORDER BY updated_at DESC
            """, (shop_id,))
            
            entries = cursor.fetchall()
            
            # Garder la premiÃ¨re entrÃ©e (la plus rÃ©cente) et supprimer les autres
            if entries:
                keep_id = entries[0][0]  # ID de la premiÃ¨re entrÃ©e (la plus rÃ©cente)
                
                # Supprimer les autres entrÃ©es
                cursor.execute("""
                    DELETE FROM analytics 
                    WHERE shop_id = ? AND id != ?
                """, (shop_id, keep_id))
                
                deleted_count = cursor.rowcount
                total_cleaned += deleted_count
                print(f"      âœ… {deleted_count} doublons supprimÃ©s, gardÃ© ID {keep_id}")
        
        print(f"\nâœ… NETTOYAGE TERMINÃ‰: {total_cleaned} doublons supprimÃ©s")
        
        print("\nğŸ”§ PHASE 2: CORRECTION DE LA STRUCTURE")
        
        # VÃ©rifier la structure actuelle
        cursor.execute("PRAGMA table_info(analytics)")
        columns = cursor.fetchall()
        
        print("   Structure actuelle de la table analytics:")
        for col in columns:
            print(f"      - {col[1]} ({col[2]}) - PK: {col[5]}")
        
        # Ajouter une contrainte unique sur shop_id si elle n'existe pas
        try:
            cursor.execute("""
                CREATE UNIQUE INDEX idx_analytics_shop_id_unique 
                ON analytics(shop_id)
            """)
            print("   âœ… Contrainte unique ajoutÃ©e sur shop_id")
        except sqlite3.OperationalError as e:
            if "already exists" in str(e):
                print("   â„¹ï¸ Contrainte unique sur shop_id dÃ©jÃ  existante")
            else:
                print(f"   âš ï¸ Erreur lors de l'ajout de la contrainte: {e}")
        
        # VÃ©rifier le rÃ©sultat final
        print("\nğŸ“Š VÃ‰RIFICATION FINALE:")
        
        cursor.execute("SELECT COUNT(*) FROM analytics")
        final_total = cursor.fetchone()[0]
        print(f"   Total des entrÃ©es aprÃ¨s nettoyage: {final_total}")
        
        cursor.execute("SELECT COUNT(DISTINCT shop_id) FROM analytics")
        final_unique = cursor.fetchone()[0]
        print(f"   Boutiques uniques aprÃ¨s nettoyage: {final_unique}")
        
        space_saved = total_entries - final_total
        print(f"   Espace libÃ©rÃ©: {space_saved} entrÃ©es supprimÃ©es")
        
        # Valider qu'il n'y a plus de doublons
        cursor.execute("""
            SELECT COUNT(*) FROM (
                SELECT shop_id, COUNT(*) as count 
                FROM analytics 
                GROUP BY shop_id 
                HAVING COUNT(*) > 1
            )
        """)
        remaining_duplicates = cursor.fetchone()[0]
        
        if remaining_duplicates == 0:
            print("   âœ… Aucun doublon restant - Nettoyage rÃ©ussi!")
        else:
            print(f"   âš ï¸ {remaining_duplicates} boutiques ont encore des doublons")
        
        # Commit des changements
        conn.commit()
        print("\nğŸ’¾ Changements sauvegardÃ©s dans la base")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors du nettoyage: {e}")
        return False
        
    finally:
        if 'conn' in locals():
            conn.close()

if __name__ == "__main__":
    fix_analytics_duplicates()
