#!/usr/bin/env python3
"""
Script pour mettre √† jour directement les shops avec toutes les m√©triques en statut "completed"
"""

import sqlite3
import requests
import json
import logging
from datetime import datetime, timezone

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def update_completed_shops_direct():
    """Met √† jour directement les shops avec toutes les m√©triques en statut completed"""
    
    # R√©cup√©rer les donn√©es de l'API
    try:
        response = requests.get('http://localhost:3000/api/shops/with-analytics')
        response.raise_for_status()
        data = response.json()
        shops = data['data']
        logger.info(f"üìä {len(shops)} shops r√©cup√©r√©s de l'API")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {e}")
        return
    
    # M√©triques principales √† v√©rifier
    main_metrics = [
        'organic_traffic', 'bounce_rate', 'average_visit_duration',
        'branded_traffic', 'conversion_rate', 'paid_search_traffic', 'live_ads'
    ]
    
    # Identifier les shops avec toutes les m√©triques
    complete_shops = []
    for shop in shops:
        has_all_metrics = True
        for metric in main_metrics:
            value = shop.get(metric, '')
            if not value or value == '' or value == 'na':
                has_all_metrics = False
                break
        
        if has_all_metrics and shop.get('scraping_status') == 'partial':
            complete_shops.append(shop)
    
    logger.info(f"üéØ {len(complete_shops)} shops √† mettre √† jour en 'completed'")
    
    if not complete_shops:
        logger.info("‚úÖ Aucun shop √† mettre √† jour")
        return
    
    # Connexion directe √† la base de donn√©es
    db_path = '/home/ubuntu/trendtrack-scraper-final/data/trendtrack.db'
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        updated_count = 0
        for shop in complete_shops:
            shop_id = shop['id']
            try:
                # Mettre √† jour le statut directement
                cursor.execute("""
                    UPDATE shops 
                    SET scraping_status = 'completed', 
                        scraping_last_update = datetime('now')
                    WHERE id = ?
                """, (shop_id,))
                
                if cursor.rowcount > 0:
                    updated_count += 1
                    logger.info(f"‚úÖ Shop {shop_id} ({shop['domain']}) - Statut mis √† jour en 'completed'")
                else:
                    logger.warning(f"‚ö†Ô∏è Shop {shop_id} non trouv√© dans la base")
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur shop {shop_id}: {e}")
        
        conn.commit()
        logger.info(f"üéØ R√âSULTAT: {updated_count}/{len(complete_shops)} shops mis √† jour")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur base de donn√©es: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    logger.info("üöÄ D√âBUT DE LA MISE √Ä JOUR DIRECTE DES STATUTS")
    update_completed_shops_direct()
    logger.info("‚úÖ MISE √Ä JOUR TERMIN√âE")
