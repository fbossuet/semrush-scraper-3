# ğŸ¤– Semrush Scraper 3 - Playwright Web Automation

Un scraper web automatisÃ© utilisant Playwright pour naviguer, se connecter et extraire des donnÃ©es de sites web.

## ğŸš€ FonctionnalitÃ©s

- âœ… **Connexion automatique** sur les sites web
- ğŸ§­ **Navigation intelligente** entre les interfaces
- ğŸ“Š **Extraction de donnÃ©es** configurables
- ğŸ“¸ **Captures d'Ã©cran** automatiques
- âš¡ **Configuration flexible** via fichiers de config
- ğŸ”§ **Mode debug** pour dÃ©veloppement
- ğŸ“± **Support multi-navigateurs** (Chrome, Firefox, Safari)

## ğŸ“¦ Installation

### 1. Installer les dÃ©pendances

```bash
npm install
```

### 2. Installer les navigateurs Playwright

```bash
npm run install-playwright
```

## ğŸ› ï¸ Configuration

### Fichier principal: `src/config.js`

Modifie ce fichier pour adapter le scraper Ã  ton site web:

```javascript
export const config = {
  // URLs du site
  loginUrl: 'https://tonsite.com/login',
  targetUrl: 'https://tonsite.com/data',
  
  // Identifiants de connexion
  credentials: {
    username: 'ton_username',
    password: 'ton_password',
    usernameSelector: '#email',    // SÃ©lecteur CSS du champ email
    passwordSelector: '#password', // SÃ©lecteur CSS du champ password
    submitSelector: 'button[type="submit"]'
  },
  
  // Ã‰lÃ©ments Ã  scraper
  selectors: {
    titre: {
      selector: 'h1.main-title',
      multiple: false
    },
    produits: {
      selector: '.product-item',
      multiple: true
    },
    liens: {
      selector: 'a.product-link',
      attribute: 'href',
      multiple: true
    }
  }
};
```

## ğŸ¯ Utilisation

### Scraper gÃ©nÃ©rique

```bash
npm start              # Lancement simple
npm run dev           # Mode dÃ©veloppement avec debug
```

### ğŸ”§ Workflow NoxTools (spÃ©cialisÃ©)

Pour utiliser NoxTools comme passerelle d'accÃ¨s :

```bash
npm run noxtools       # Workflow NoxTools complet
npm run noxtools-dev   # Mode dÃ©veloppement NoxTools
```

**ğŸ“‹ Guide complet NoxTools**: Voir [NOXTOOLS-GUIDE.md](NOXTOOLS-GUIDE.md)

### Exemples d'utilisation

#### 1. Scraping basique

```javascript
import { WebScraper } from './src/scraper.js';

const scraper = new WebScraper();
await scraper.init();

// Connexion
await scraper.login('https://monsite.com/login', {
  username: 'user',
  password: 'pass',
  usernameSelector: '#email',
  passwordSelector: '#password'
});

// Navigation
await scraper.navigateToInterface('https://monsite.com/data');

// Extraction
const data = await scraper.scrapeData({
  titles: { selector: '.title', multiple: true },
  prices: { selector: '.price', multiple: true }
});

console.log(data);
await scraper.close();
```

#### 2. Navigation complexe avec attentes

```javascript
// Attendre qu'un Ã©lÃ©ment apparaisse
await scraper.waitForElement('.data-table');

// Cliquer sur des Ã©lÃ©ments
await scraper.page.click('.menu-button');

// Remplir des formulaires
await scraper.page.fill('#search', 'terme de recherche');

// Attendre le chargement
await scraper.page.waitForLoadState('networkidle');
```

#### 3. Pagination automatique

```javascript
let allData = [];
let page = 1;

while (await scraper.page.$('.next-page:not(.disabled)')) {
  console.log(`Scraping page ${page}...`);
  
  const pageData = await scraper.scrapeData(config.selectors);
  allData.push(...pageData.items);
  
  await scraper.page.click('.next-page');
  await scraper.page.waitForLoadState('networkidle');
  page++;
}
```

## ğŸ“ Structure du projet

```
semrush-scraper-3/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.js         # Classe principale du scraper
â”‚   â”œâ”€â”€ config.js          # Configuration (URLs, sÃ©lecteurs, etc.)
â”‚   â”œâ”€â”€ noxtools-scraper.js # Scraper spÃ©cialisÃ© NoxTools
â”‚   â””â”€â”€ example.js         # Exemples d'utilisation
â”œâ”€â”€ screenshots/           # Captures d'Ã©cran automatiques
â”œâ”€â”€ package.json          # DÃ©pendances et scripts
â”œâ”€â”€ README.md            # Documentation gÃ©nÃ©rale
â”œâ”€â”€ NOXTOOLS-GUIDE.md    # Guide spÃ©cifique NoxTools
â””â”€â”€ .gitignore           # Fichiers Ã  ignorer
```

## ğŸ”§ Options de configuration

### Navigateur
- `headless`: true/false (mode sans interface)
- `slowMo`: dÃ©lai entre actions (ms)
- `viewport`: taille de la fenÃªtre

### SÃ©lecteurs
- `selector`: sÃ©lecteur CSS de l'Ã©lÃ©ment
- `multiple`: true pour rÃ©cupÃ©rer plusieurs Ã©lÃ©ments
- `attribute`: attribut HTML Ã  extraire (href, src, etc.)

### Timeouts
- `navigation`: timeout pour navigation (ms)
- `element`: timeout pour attente d'Ã©lÃ©ments (ms)

## ğŸš¨ Conseils d'utilisation

### 1. Trouver les bons sÃ©lecteurs CSS

Utilise les outils de dÃ©veloppeur de ton navigateur:
1. F12 pour ouvrir les dev tools
2. Clique sur l'icÃ´ne de sÃ©lection
3. Clique sur l'Ã©lÃ©ment Ã  scraper
4. Copie le sÃ©lecteur CSS

### 2. GÃ©rer les sites avec authentification

```javascript
// Attendre la redirection aprÃ¨s connexion
await scraper.page.waitForURL('**/dashboard**');

// VÃ©rifier si la connexion a rÃ©ussi
const isLoggedIn = await scraper.page.$('.user-menu');
if (!isLoggedIn) {
  throw new Error('Connexion Ã©chouÃ©e');
}
```

### 3. Contourner les protections anti-bot

```javascript
// User agent rÃ©aliste
userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',

// DÃ©lais alÃ©atoires
slowMo: Math.random() * 200 + 100,

// Mouvements de souris naturels
await scraper.page.mouse.move(100, 100);
await scraper.page.mouse.move(200, 200);
```

## ğŸ› Debugging

### Mode debug activÃ©

```javascript
// Dans config.js
debug: {
  screenshots: true,  // Capture automatique
  logs: true,        // Logs dÃ©taillÃ©s
  slowMode: true     // Ralentir l'exÃ©cution
}
```

### Captures d'Ã©cran manuelles

```javascript
await scraper.takeScreenshot('debug-step-1.png');
```

### Logs dÃ©taillÃ©s

```javascript
// Activer les logs Playwright
DEBUG=pw:api npm start
```

## âš ï¸ ConsidÃ©rations lÃ©gales

- âœ… Respecte les `robots.txt` des sites
- âœ… N'abuse pas des serveurs (dÃ©lais entre requÃªtes)
- âœ… Respecte les conditions d'utilisation
- âœ… Utilise tes propres comptes/identifiants

## ğŸ”„ Scripts disponibles

```bash
npm start                    # Lancer le scraper gÃ©nÃ©rique
npm run dev                 # Mode dÃ©veloppement gÃ©nÃ©rique
npm run noxtools            # Workflow NoxTools complet  
npm run noxtools-dev        # Mode dÃ©veloppement NoxTools
npm run install-playwright  # Installer les navigateurs
npm test                    # Tests (Ã  implÃ©menter)
```

## ğŸ†˜ ProblÃ¨mes courants

### "Browser not found"
```bash
npm run install-playwright
```

### "Element not found"
- VÃ©rifier les sÃ©lecteurs CSS
- Augmenter les timeouts
- Ajouter des attentes explicites

### "Login failed"
- VÃ©rifier les identifiants
- Adapter les sÃ©lecteurs de connexion
- VÃ©rifier les CAPTCHA

### "Page not loading"
- VÃ©rifier l'URL
- Augmenter le timeout de navigation
- VÃ©rifier la connexion internet

## ğŸ“ Support

Pour toute question ou problÃ¨me, consulte:
- [Documentation Playwright](https://playwright.dev/)
- [Exemples de sÃ©lecteurs CSS](https://www.w3schools.com/cssref/css_selectors.asp)

Bon scraping ! ğŸ¯
